{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb0c4ee",
   "metadata": {},
   "source": [
    "# Lightning Flash Dataset: Spark Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983afdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pyspark library : 3.4.1\n",
    "import warnings\n",
    "\n",
    "import pyspark.sql.functions as F \n",
    "import pyspark.sql.types as T \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f5cf581",
   "metadata": {},
   "source": [
    "## Load Data - Geospatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55614f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Batch load - Geospatial coordinates\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# latitude data frame\n",
    "lat_sdf = spark.read \\\n",
    "            .format('csv') \\\n",
    "            .load(\"*.lat.csv.test\", header=True, inferSchema=True) \n",
    "# longitude data frame\n",
    "lon_sdf = spark.read \\\n",
    "               .format('csv') \\\n",
    "               .load(\"*.lon.csv.test\", header=True, inferSchema=True)   \n",
    "# geospatial (lat, lon)          \n",
    "geo_sdf = lat_sdf.join(lon_sdf,on=\"ts_date\",how=\"inner\") \\\n",
    "                 .withColumnRenamed(\"ts_date\", \"timestamp\") \\\n",
    "                 .orderBy(\"timestamp\", ascending=True) \\\n",
    "                 .show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81421bae",
   "metadata": {},
   "source": [
    "## Load Data - Energy Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98749ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Structured Streaming - Flash energy discharges\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "energySchema = T.StructType().add(\"ts_date\", \"timestamp\").add(\"energy\", \"double\")\n",
    "energy_sdf = spark \\\n",
    "            .readStream.schema(energySchema) \\\n",
    "            .option(\"maxFilesPerTrigger\", 1) \\\n",
    "            .format(\"csv\") \\\n",
    "            .load(\"*.ene.csv.test\", header=True, inferSchema=True) \\\n",
    "            .withColumnRenamed(\"ts_date\", \"timestamp\") \\\n",
    "            .writeStream.format('console') \\\n",
    "            .trigger(processingTime=\"5 seconds\") \\\n",
    "            .outputMode('append') \\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of stream\n",
    "energy_sdf.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off the stream\n",
    "energy_sdf.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d39ad",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2ae3c",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.ss/index.html\n",
    "\n",
    "https://www.projectpro.io/article/pyspark-learning-spark-with-python/554\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
